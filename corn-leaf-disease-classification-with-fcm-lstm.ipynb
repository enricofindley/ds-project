{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/enricofindley/corn-leaf-disease-classification-with-fcm-lstm?scriptVersionId=140355100\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# README\n#### This is my thesis project, if some of you need to use a portion or all of my code feel free to copy it but please cite my thesis <a href=\"http://repo.darmajaya.ac.id/11576/\">here</a>","metadata":{}},{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"# install split folders for splitting image data into train,val, and test.\n%pip install split-folders\n%pip install scikit-fuzzy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import StandardScaler\nimport os\nimport cv2\nimport skfuzzy as fuzz\nimport pandas as pd \nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport warnings\nfrom tqdm import tqdm\nimport splitfolders\nimport shutil\nfrom keras.utils import np_utils\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-17T04:19:21.657459Z","iopub.execute_input":"2023-08-17T04:19:21.658175Z","iopub.status.idle":"2023-08-17T04:19:47.727354Z","shell.execute_reply.started":"2023-08-17T04:19:21.658137Z","shell.execute_reply":"2023-08-17T04:19:47.726112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Dataset Splitting\n\nIn this part we are going to do:\n* Create folder 'data' which later contain raw splitted dataset and segmented dataset\n* Using <code>splitfolders</code> library to handle splitting the image file\n* Adding oversampling to <code>splitfolders</code> so the dataset will become balanced","metadata":{}},{"cell_type":"code","source":"file_path='/kaggle/input/new-bangladeshi-crop-disease/BangladeshiCrops/BangladeshiCrops/Crop___Disease/Corn'\nsplitted_folder='data'\n# if folder 'data' not exist it make the folder 'data'\nif not os.path.exists(splitted_folder):\n   os.makedirs(splitted_folder)\n# else if folder 'data' not exist then it will delete it then make the folder 'data'\nelse:\n  # Deleting an non-empty folder\n  shutil.rmtree(splitted_folder, ignore_errors=True)\n  print(\"Deleted '%s' directory successfully\" % splitted_folder)\n\n  os.makedirs(splitted_folder)\n\n# make splitfolders function to split dataset\ndef train_test_valid(images_folder=file_path,splitted_folder=splitted_folder):\n  input_folder = images_folder\n  output_folder = splitted_folder\n  splitfolders.fixed(input_folder,output_folder, seed = 1337, fixed = (100,100), oversample=True, group_prefix = None)\n\n# run function train_test_valid()\ntrain_test_valid()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:08:10.814318Z","iopub.execute_input":"2023-08-17T04:08:10.815084Z","iopub.status.idle":"2023-08-17T04:08:42.022143Z","shell.execute_reply.started":"2023-08-17T04:08:10.815046Z","shell.execute_reply":"2023-08-17T04:08:42.021226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Declaring Global Variables","metadata":{}},{"cell_type":"code","source":"CATEGORIES = [\"Corn___Common_Rust\",\"Corn___Gray_Leaf_Spot\",\"Corn___Healthy\", \"Corn___Northern_Leaf_Blight\"]\nIMG_SIZE = 128\n\nTRAIN_DATADIR = \"/kaggle/working/data/train\"\nVALIDATION_DATADIR = \"/kaggle/working/data/val\"\nTEST_DATADIR = \"/kaggle/working/data/test\"\n\nSEG_TRAIN_DATADIR = \"/kaggle/working/data/segmented/train\"\nSEG_VALIDATION_DATADIR = \"/kaggle/working/data/segmented/val\"\nSEG_TEST_DATADIR = \"/kaggle/working/data/segmented/test\"\nclusters = [2]","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:19:55.143747Z","iopub.execute_input":"2023-08-17T04:19:55.14412Z","iopub.status.idle":"2023-08-17T04:19:55.152332Z","shell.execute_reply.started":"2023-08-17T04:19:55.144088Z","shell.execute_reply":"2023-08-17T04:19:55.151256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fuzzy C-Means (FCM) Image Segmentation\n\nFirst algorithm used to do image segmentation is Fuzzy C-Means (FCM), we are going to do:\n* Declaring function to change color of segmented region from FCM algorithm\n* Convert image into grayscale then resize it to 128x128 and reshape it into 2 dimensional array as <code>uint8</code> type\n* Segmenting the image using FCM then convert it to binary image and highlight the segmented area with alpha blending\n* Put segmented image data into an array before giving it to LSTM model","metadata":{}},{"cell_type":"code","source":"# function to change color of segmented region from FCM algorithm\ndef change_color_fuzzycmeans(cluster_membership, clusters):\n    img = []\n    for pix in cluster_membership.T:\n        img.append(clusters[np.argmax(pix)])\n    return img\n\n# segmenting image with FCM\ndef segmentImage(data_path, result_path):\n    labels=[]\n    segmented_images=[]\n    for category in CATEGORIES:  \n        index=0\n        path = os.path.join(data_path,category)  # create path to image\n        seg_path=os.path.join(result_path,category)  # create path to image\n        class_num = CATEGORIES.index(category)  # get the classification\n        \n        for img in os.listdir(path):  # iterate over each image \n            img_input = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n            img_resized= cv2.resize(img_input, (IMG_SIZE,IMG_SIZE), interpolation = cv2.INTER_AREA)\n            gray_img = img_resized.reshape(( img_resized.shape[0] *  img_resized.shape[1], 1))          \n            img = np.reshape(gray_img, (IMG_SIZE,IMG_SIZE,1)).astype(np.uint8)\n            shape = np.shape(img)\n\n            for i,cluster in enumerate(clusters):                  \n                # Fuzzy C Means\n                    \n                cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(gray_img.T, cluster, 2, error=0.00001, maxiter=100, init=None,seed=42)  \n                new_img = change_color_fuzzycmeans(u,cntr)\n                    \n                fuzzy_img = np.reshape(new_img,shape).astype(np.uint8)  \n                ret, seg_img = cv2.threshold(fuzzy_img,np.max(fuzzy_img)-1,255,cv2.THRESH_BINARY)\n\n                # Add the color mask to the original image using alpha blending\n                alpha = 0.6\n                result = cv2.addWeighted(img, alpha, seg_img, 1-alpha, 0)     \n\n            segmented_images.append(seg_img)\n            labels.append(class_num)\n            index=index+1\n            cv2.imwrite(os.path.join(seg_path , 'segmented'+str(index)+'.png'), result)\n    return segmented_images,labels\n\n# run function segmentImage() for all dataset part\ntrain_img, train_label = segmentImage(TRAIN_DATADIR, SEG_TRAIN_DATADIR)\nval_img, val_label = segmentImage(VALIDATION_DATADIR, SEG_VALIDATION_DATADIR)\ntest_img, test_label = segmentImage(TEST_DATADIR, SEG_TEST_DATADIR)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:23:32.302857Z","iopub.execute_input":"2023-08-17T04:23:32.303242Z","iopub.status.idle":"2023-08-17T04:23:32.316381Z","shell.execute_reply.started":"2023-08-17T04:23:32.303211Z","shell.execute_reply":"2023-08-17T04:23:32.315423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating segmented image data for training, validation, and testing with LSTM model.","metadata":{}},{"cell_type":"code","source":"training_data = []\nval_data = []\ntest_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:  \n\n        path = os.path.join(SEG_TRAIN_DATADIR,category)  # create path to image\n        class_num = CATEGORIES.index(category)  # get the classification\n\n        for img in tqdm(os.listdir(path)):  # iterate over each image \n            try:\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n                training_data.append([img_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass\n            #except OSError as e:\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n            #except Exception as e:\n            #    print(\"general exception\", e, os.path.join(path,img))\n\n\ndef create_validation_data():\n    for category in CATEGORIES:  #\n\n        path = os.path.join(SEG_VALIDATION_DATADIR,category)  \n        class_num = CATEGORIES.index(category)\n\n        for img in tqdm(os.listdir(path)):  \n            try:\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n                val_data.append([img_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass\n            #except OSError as e:\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n            #except Exception as e:\n            #    print(\"general exception\", e, os.path.join(path,img))\n\ndef create_test_data():\n    for category in CATEGORIES:  \n\n        path = os.path.join(SEG_TEST_DATADIR,category)  # create path to image\n        class_num = CATEGORIES.index(category)  # get the classification\n\n        for img in tqdm(os.listdir(path)):  # iterate over each image \n            try:\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n                training_data.append([img_array, class_num])  # add this to our training_data\n            except Exception as e:  # in the interest in keeping the output clean...\n                pass\n            #except OSError as e:\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n            #except Exception as e:\n            #    print(\"general exception\", e, os.path.join(path,img))\n            \ncreate_training_data()\ncreate_validation_data()\ncreate_test_data()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T04:21:10.399057Z","iopub.execute_input":"2023-08-17T04:21:10.399418Z","iopub.status.idle":"2023-08-17T04:21:32.008745Z","shell.execute_reply.started":"2023-08-17T04:21:10.399387Z","shell.execute_reply":"2023-08-17T04:21:32.007549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing before Training","metadata":{}},{"cell_type":"code","source":"x_train = []\ny_train = []\nx_val = []\ny_val = []\nx_test = []\ny_test = []\n\nfor features,label in training_data:\n    x_train.append(features)\n    y_train.append(label)\nfor features,label in val_data:\n    x_val.append(features)\n    y_val.append(label)\nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = (np.array(x_train)) \nx_val = (np.array(x_val))\nx_test = (np.array(x_test))\n\ny_train=np.array(y_train)\ny_val=np.array(y_val)\ny_test=np.array(y_test)\n\nx_train = (x_train.astype('float32'))/255\nx_val = (x_val.astype('float32'))/255\nx_test = (x_test.astype('float32'))/255","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training and Evaluation with K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"# Model configuration\nearlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=8)\nbatch_size = 128\nno_epochs = 50\nverbosity = 1\nnum_folds = 10\n\n\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# Merge inputs and targets\ninputs = np.concatenate((x_train, x_val), axis=0)\ntargets = np.concatenate((y_train, y_val), axis=0)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, val in kfold.split(inputs, targets):\n\n  # Define the model architecture\n  model = keras.Sequential()\n  model.add(keras.Input(shape=(128,128)))\n  model.add(keras.layers.LSTM(192))\n  model.add(keras.layers.Dense(4, activation='softmax'))\n  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(learning_rate=1e-3),metrics = ['accuracy'])\n\n\n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n  history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              validation_data=(inputs[val], targets[val]),          \n              epochs=no_epochs,\n              verbose=verbosity)\n\n  # Generate generalization metrics\n  scores = model.evaluate(inputs[val], targets[val], verbose=0)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n  model.save(str(fold_no)+'foldmodel.h5')\n  # Increase fold number\n  fold_no = fold_no + 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining helper function for testing","metadata":{}},{"cell_type":"code","source":"def plot_image(i, predictions_array, true_label, img):\n  true_label, img = true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% \\n ({})\".format(CATEGORIES[predicted_label],\n                                100*np.max(predictions_array),\n                                CATEGORIES[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  true_label = true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(4), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"predict_model = keras.models.load_model('fcm_final.h5')\nnew_time = time()\npredictions = predict_model.predict(x_test)\nprint(time() - new_time,'seconds')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DATA_INDEX = 0\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplot_image(TEST_DATA_INDEX, predictions[TEST_DATA_INDEX], y_test, x_test)\nplt.subplot(1,2,2)\nplot_value_array(TEST_DATA_INDEX, predictions[TEST_DATA_INDEX],  y_test)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_rows = 100\nnum_cols = 4\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(360,400):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], y_test, test_img)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], y_test)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}